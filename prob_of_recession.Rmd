---
title: "Probability of Recession"
author: "William Chiu"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

```

## Summary

Forecast the probability of a recession in the next 6 months using the following predictors:

1.  Spread between 10Y CMT and Effective Federal Funds Rate
2.  YOY change in Unemployment Rate
3.  YOY growth in CPI-U
4.  YOY change in Effective Federal Funds Rate
5.  Adstock transformations of predictors

## Extract Historical Data

Refer to this [vignette](https://cran.r-project.org/web/packages/fredr/vignettes/fredr.html) for FRED data access.

```{r}
library(tidyverse)
library(lubridate)
library(scam)
library(fredr)
library(effects)
library(car)
library(MLmetrics)
library(caret)
library(pdp)
library(gridExtra)
library(mboost)
library(gbm)
library(import)
library(randomForest)
library(glmnet)
library(gtsummary)

```

```{r}
series_id <- c("FEDFUNDS", "GS10", "USREC", "UNRATE", "CPIAUCSL")

full_data <- map_dfr(series_id, function(x) {
  fredr(
    series_id = x,
    observation_start = as.Date("1950-01-01"),
    observation_end = as.Date("2022-12-01")
  )
})
```

## Pivot Wider

```{r}
full_data_wide_raw <- full_data %>% 
  arrange(date) %>% 
  select(date, series_id, value) %>% 
  pivot_wider(id_cols=date, names_from = series_id,
              values_from = value)
```

## Calculate Features/Predictors

```{r}
full_data_wide_features <- full_data_wide_raw %>% 
  arrange(date) %>% 
  mutate(SPRD_10YCMT_FEDFUNDS = GS10 - FEDFUNDS,
         D_UNRATE = UNRATE - lag(UNRATE, 12),
         G_CPIU = (CPIAUCSL / lag(CPIAUCSL, 12) - 1) * 100,
         D_EFFR = FEDFUNDS - lag(FEDFUNDS, 12),
         D_GS10 = GS10 - lag(GS10, 12)
         ) %>% 
  mutate(across(
    .cols=c(SPRD_10YCMT_FEDFUNDS, D_UNRATE,
               G_CPIU, D_EFFR, GS10, D_GS10),
    .fns=list(lag1 = ~lag(.x, 1),
         lag3 = ~lag(.x, 3),
         lag6 = ~lag(.x, 6),
         lag9 = ~lag(.x, 9),
         lag12 = ~lag(.x, 12))
  )) %>% 
  select(-CPIAUCSL) %>% ## index rises with time
  drop_na()
```

## Calculate Adstock

The adstock transformation is an auto-regressive transformation of a time series. The transformation takes into account past values of the time series. The intuition is that past values of the time series has a contemporaneous effect on the outcome.

$$AdStock(x_t) = x_t + \theta AdStock(x_{t-1})$$

where $0 < \theta < 1$.

The parameters cannot be estimated easily with least squares or logistic regression. Instead, we assume a range of potential values between 0.05 and 0.85.

```{r}
full_data_wide_features_adstock <- full_data_wide_features %>% 
  arrange(date) %>% 
    mutate(across(
    .cols=c(UNRATE:D_GS10),
    .fns=list(adstkL = ~stats::filter(.x,
                                     filter=0.05,
                                     method="recursive") ,
         adstkM = ~stats::filter(.x,
                                     filter=0.45,
                                     method="recursive") ,
         adstkHL = ~stats::filter(.x,
                                     filter=0.65,
                                     method="recursive"),
         adstkHM = ~stats::filter(.x,
                                     filter=0.75,
                                     method="recursive"),
         adstkHH = ~stats::filter(.x,
                                     filter=0.85,
                                     method="recursive")
  ))) %>% 
  mutate(constant=1)
```


## Recession in next 6 months

```{r}
full_data_wide <- full_data_wide_features_adstock %>% 
  arrange(date) %>% 
  mutate(USREC_LEAD1 = lead(USREC, 1),
         USREC_LEAD2 = lead(USREC, 2),
         USREC_LEAD3 = lead(USREC, 3),
         USREC_LEAD4 = lead(USREC, 4),
         USREC_LEAD5 = lead(USREC, 5),
         USREC_LEAD6 = lead(USREC, 6),
         FUTREC = pmax(USREC_LEAD1, USREC_LEAD2, USREC_LEAD3,
                                 USREC_LEAD4, USREC_LEAD5, USREC_LEAD6)) %>% 
  drop_na() %>% 
  select( -USREC_LEAD1, -USREC_LEAD2, -USREC_LEAD3,
         -USREC_LEAD4, -USREC_LEAD5, -USREC_LEAD6) 
```



## Split Train/Test

```{r}
full_size <- nrow(full_data_wide)

train_size <- floor(full_size*0.80)

train_id <- seq.int(1,train_size,1)

full_data_wide$constant <- 1

train_data <- full_data_wide[train_id,]
test_data <- full_data_wide[-train_id,]


tbl_summary(train_data)
```


## Automated Approaches

1. Gradient Boosting for Additive Models
2. eXtreme Gradient Boosting Trees
3. Random Forest
4. Stepwise Regression
5. Elastic Net (Lasso)
6. Multivariate Adaptive Regression Splines
7. Null Model: Intercept-only Model

```{r}
fitControl <- trainControl(method = "timeslice",
                           initialWindow=392,
                           horizon=120,
                           fixedWindow=FALSE,
                           skip=119,
                           ## Estimate class probabilities
                           classProbs = TRUE,
                           ## Evaluate performance using 
                           ## the following function
                           summaryFunction = mnLogLoss)

train_yes_no <- train_data %>% 
  mutate(FUTREC = case_when(FUTREC == 1 ~ "yes",
                            TRUE ~ "no"))

train_yes_no$FUTREC <- factor(train_yes_no$FUTREC, 
                              levels=c("yes","no"))

train_yes_no_relevel <- train_yes_no

train_yes_no_relevel$FUTREC <- relevel(
  train_yes_no_relevel$FUTREC, ref="no"

)

```



```{r}
library(doParallel)

cl <- makePSOCKcluster(5)
registerDoParallel(cl)

set.seed(111)

gam_mod <- train(
  FUTREC ~ . - date - USREC - constant,
  data = train_yes_no,
  method = "gamboost",
  trControl = fitControl,
  metric = "logLoss",
  tuneLength = 10,
  family = Binomial()
)

xgb_mod <- train(
  FUTREC ~ . - date - USREC - constant,
  data = train_yes_no,
  method = "xgbTree",
  trControl = fitControl,
  metric = "logLoss",
  tuneLength = 10,
  objective  = "binary:logistic"
)

rf_mod <- train(
  FUTREC ~ . - date - USREC - constant,
  data = train_yes_no,
  method = "rf",
  trControl = fitControl,
  metric = "logLoss",
  tuneLength = 10,
  importance = TRUE
)

stepwise_mod <- train(
  FUTREC ~ . - date - USREC - constant,
  data = train_yes_no_relevel,
  method = "glmStepAIC",
  trControl = fitControl,
  metric = "logLoss",
  tuneLength = 10,
  family = binomial,
  trace = 0,
  k = 5 * log(nrow(train_yes_no)),
  direction = "forward"
)

glmnet_mod <- train(
  FUTREC ~ . - date - USREC - constant,
  data = train_yes_no,
  method = "glmnet",
  trControl = fitControl,
  metric = "logLoss",
  tuneLength = 10,
  family = "binomial"
)

earth_mod <- train(
  FUTREC ~ . - date - USREC - constant,
  data = train_yes_no,
  method = "earth",
  trControl = fitControl,
  metric = "logLoss",
  tuneLength = 10,
  glm = list(family = binomial)
)

null_mod <- train(
  FUTREC ~ constant,
  data = train_yes_no,
  method = "glm",
  trControl = fitControl,
  metric = "logLoss",
  family = binomial
)




stopCluster(cl)

```




```{r}
resamps <- resamples(list(XGB = xgb_mod,
                          GAM = gam_mod,
                          RF = rf_mod,
                          Step = stepwise_mod,
                          Lasso = glmnet_mod,
                          MARS = earth_mod,
                          Null = null_mod)
                     )
summary(resamps)

dotplot(resamps, metric = "logLoss", conf.level=0.5)
```

```{r}
gam_mod$bestTune
```

```{r}
df_imp <- as.data.frame(
  varimp(gam_mod$finalModel)) %>% 
  select(variable, reduction) %>% 
  arrange(desc(reduction))

df_imp$variable <- as.character(df_imp$variable)

knitr::kable(df_imp)
```

```{r}
pdp.top1 <- partial(gam_mod,
          pred.var = df_imp$variable[1],
          plot = TRUE,
          rug = TRUE)

pdp.top2 <- partial(gam_mod,
          pred.var = df_imp$variable[2],
          plot = TRUE,
          rug = TRUE)

pdp.top3 <- partial(gam_mod,
    pred.var = df_imp$variable[3],
    plot = TRUE,
    chull = TRUE
  )

pdp.top4 <- partial(gam_mod,
    pred.var = df_imp$variable[4],
    plot = TRUE,
    chull = TRUE
  )

pdp.top5 <- partial(gam_mod,
    pred.var = df_imp$variable[5],
    plot = TRUE,
    chull = TRUE
  )

pdp.top6 <- partial(gam_mod,
    pred.var = df_imp$variable[6],
    plot = TRUE,
    chull = TRUE
  )

grid.arrange(pdp.top1, pdp.top2, pdp.top3,
             pdp.top4, pdp.top5, pdp.top6, ncol = 3)
```



## Monotone Gradient Boosting (with peeking)

Peeking means we use the insights from the automated models to choose variables in subsequent models. This is technically cheating and causes the cross-validation errors to be artificially low. This is addressed in the test set which does not have peeking bias.

```{r}
top_predictors <- head(df_imp$variable)

best_predictor <- head(top_predictors, 1)

top_fmla <- as.formula(paste0("FUTREC ~", 
                              paste0(top_predictors,
                                     collapse=" + ")))

top1_fmla <- as.formula(paste0("FUTREC ~", 
                              paste0(best_predictor,
                                     collapse=" + ")))

constraints <- c(-1, 1, -1, -1, 1, -1)

monotone_constraints <- paste0(top_predictors, " = ", constraints, collapse=", \n")

cat(monotone_constraints)
```


```{r}
library(doParallel)

cl <- makePSOCKcluster(5)
registerDoParallel(cl)

myGrid <- expand.grid(n.trees=seq(5,100,5),
                      interaction.depth=1,
                      shrinkage=c(0.01, 0.025, 0.05, 0.1,
                                  0.2, 0.3, 0.4, 0.5, 0.6,
                                  0.7, 0.8, 0.85, 0.9, 0.95,
                                  0.99),
                      n.minobsinnode=c(5,10,20,40,50,60,
                                       70, 80, 90, 100))

gbm_mod_mono <- train(
  top_fmla,
  data = train_yes_no,
  method = "gbm",
  trControl = fitControl,
  metric = "logLoss",
  tuneGrid = myGrid,
  distribution = "bernoulli",
  verbose=FALSE,
  var.monotone = constraints
  
)

stopCluster(cl)

```


```{r}
gbm_mod_mono$bestTune
```

```{r}
varImp(gbm_mod_mono)
```


```{r}
pdp.top1 <- partial(gbm_mod_mono,
          pred.var = top_predictors[1],
          plot = TRUE,
          rug = TRUE)

pdp.top2 <- partial(gbm_mod_mono,
          pred.var =  top_predictors[2],
          plot = TRUE,
          rug = TRUE)

pdp.top3 <- partial(gbm_mod_mono,
    pred.var =  top_predictors[3],
    plot = TRUE,
    chull = TRUE
  )

pdp.top4 <- partial(gbm_mod_mono,
    pred.var =  top_predictors[4],
    plot = TRUE,
    chull = TRUE
  )

pdp.top5 <- partial(gbm_mod_mono,
    pred.var =  top_predictors[5],
    plot = TRUE,
    chull = TRUE
  )

pdp.top6 <- partial(gbm_mod_mono,
    pred.var =  top_predictors[6],
    plot = TRUE,
    chull = TRUE
  )



grid.arrange(pdp.top1, pdp.top2, pdp.top3,
             pdp.top4, pdp.top5, pdp.top6, ncol = 3)
```


## One-Variable Logistic Regression (with peeking)

```{r}
library(doParallel)

cl <- makePSOCKcluster(5)
registerDoParallel(cl)

logit_mod <- train(
  top1_fmla,
  data = train_yes_no_relevel,
  method = "glm",
  trControl = fitControl,
  metric = "logLoss",
  family=binomial
)

stopCluster(cl)

summary(logit_mod)
```

```{r}
resamps <- resamples(list(XGB = xgb_mod,
                          GAM = gam_mod,
                          RF = rf_mod,
                          Step = stepwise_mod,
                          Lasso = glmnet_mod,
                          MARS = earth_mod,
                          GBM_mono = gbm_mod_mono,
                          Null = null_mod,
                          Logit = logit_mod)
                     )
summary(resamps)

dotplot(resamps, metric = "logLoss", conf.level=0.5)
```

## Shape-Constrained GAM (with peeking)


```{r}
scam_mod <- scam(FUTREC ~ s(SPRD_10YCMT_FEDFUNDS_adstkHH, bs="mpd") +
                   s(D_UNRATE, bs="mpi") +
                   s(GS10, bs="mpd"),
                 data=train_data, family=binomial()
                 )

summary(scam_mod)

plot(scam_mod,pages=1,se=FALSE,
     all.terms=TRUE)

```



## Logit with Knots (with peeking)

```{r}
logit_mod_knot <- glm(FUTREC ~ SPRD_10YCMT_FEDFUNDS_adstkHH +
                   D_UNRATE + 
                   pmax(0,D_UNRATE - 0.25) +
                   GS10 ,
                   data=train_data, family=binomial)

summary(logit_mod_knot)

```


## Effect Plot for Knots

```{r}
plot(predictorEffects(logit_mod_knot, focal.levels=1000),
     main=NULL,
     axes = list(
       grid = TRUE,
       x = list(rug = FALSE),
       y = list(type = "link")
     ))
```


## Performance Metrics

```{r}
test_preds <- predict(logit_mod, newdata=test_data, type="prob")[,"yes"]
null_preds <- predict(null_mod, newdata=test_data, type="prob")[,"yes"]
knot_preds <- predict(logit_mod_knot, newdata=test_data, type="response")
scam_preds <- predict(scam_mod, newdata=test_data, type="response")
gam_preds <- predict(gam_mod, newdata=test_data, type="prob")[,"yes"]
gbm_mono_preds <- predict(gbm_mod_mono, newdata=test_data, type="prob")[,"yes"]
mars_preds <- predict(earth_mod, newdata=test_data, type="prob")[,"yes"]
  
  


perf <- function(lst_preds, f_metric=caTools::colAUC, metricname="ROC-AUC"){
  map_dfr(lst_preds, function(x){
  f_metric(x, test_data$FUTREC)
}) %>% 
  pivot_longer(everything(), names_to="model", values_to=metricname) %>% 
  knitr::kable()
}

myPreds <- list(logit_reg=test_preds, null_model=null_preds,
                knot_reg=knot_preds, scam_mod = scam_preds,
                gam_mod=gam_preds, gbm_mono=gbm_mono_preds,
                mars_mod=mars_preds)

perf(myPreds, caTools::colAUC, "ROC-AUC")
perf(myPreds, MLmetrics::LogLoss, "LogLoss")
```

## Probability of Recession (Most Recent Month)

```{r}

curr_data <- tail(full_data_wide_features_adstock, 1)

curr_data$date
```


```{r}

mods <- list(
  logistic_reg = logit_mod,
  scam_mod = scam_mod,
  knot_mod = logit_mod_knot,
  baseline = null_mod,
  gam_mod = gam_mod,
  gbm_mod_mono = gbm_mod_mono,
  mars_mod = earth_mod
)

score_fun <- function(mods, dat) {
  output <- map_dfc(.x = mods, .f = function(x) {
    if(class(x)[1] != "train"){
      predict(x, newdata = dat, type = "response")
    } else(
       predict(x, newdata = dat, type = "prob")[,"yes"]

    )
    
  }) %>%
    pivot_longer(everything(), names_to = "model",
                 values_to = "prob_rec")
  
  output$prob_rec <- scales::percent(output$prob_rec)
  
  return(output)
}


knitr::kable(score_fun(mods, curr_data))
```




## Backtesting

```{r}
full_data_bktst <- full_data_wide_features_adstock

bkst_fun <- function(mods, dat) {
  output <- map_dfc(.x = mods, .f = function(x) {
    if(class(x)[1] != "train"){
      predict(x, newdata = dat, type = "response")
    } else(
       predict(x, newdata = dat, type = "prob")[,"yes"]

    )
    
  }) 
  
  output$date <- dat$date
  
  output <- output%>%
    pivot_longer(-date, names_to = "model",
                 values_to = "prob_rec")
  
  return(output)
}

df_plot <- bkst_fun(mods, full_data_bktst)

actuals <- full_data_bktst %>% 
  mutate(model="actuals") %>% 
  select(date, model, prob_rec=USREC)

df_plot_final <- bind_rows(df_plot, actuals)

df_plot_final <- df_plot_final %>% 
  mutate(epoc = case_when(date <= "1995-01-01" ~ "1_Before 1995",
                          TRUE ~ "2_After 1995")
  )

df_plot_logit_scam <- df_plot_final %>% 
  filter(model %in% c('actuals', 'baseline',
                      'logistic_reg',
                      'scam_mod', 'gbm_mod_mono'))

df_plot_knots_gbm <- df_plot_final %>% 
  filter(model %in% c('actuals', 'baseline',
                      'knot_mod',
                      'gam_mod',
                      'mars_mod'))
```

```{r}
ggplot(df_plot_logit_scam, aes(x=date, y=prob_rec, group=model,
                          linetype=model, color=model)) +
  geom_line() +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(vars(epoc), scales="free", nrow=2)
```

```{r}
ggplot(df_plot_knots_gbm, aes(x=date, y=prob_rec, group=model,
                          linetype=model, color=model)) +
  geom_line() +
  theme_bw() +
  theme(legend.position = "bottom") +
  facet_wrap(vars(epoc), scales="free", nrow=2)
```


